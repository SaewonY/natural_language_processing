{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Lexicon => 사전(해시 테이블) => 단어:위치, 단어:위치, ... <br>\n",
    "+ Posting => 문서:빈도:다음위치, 문서:빈도:다음위치, ... <br>\n",
    "+ Local Indexing => Merge(위치를 조정, linked list) <br>\n",
    "+ Collection(문서집합), Lexicon(사전)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = {\n",
    "    ('Document1', 'This is a sample'),\n",
    "    ('Document2', 'This is another sample'),\n",
    "    ('Document3', 'This is not a sample')\n",
    "}\n",
    "\n",
    "globalLexicon = dict()\n",
    "globalDocument = list()\n",
    "globalPosting = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'this': 9, 'is': 10, 'not': 2, 'a': 11, 'sample': 12, 'another': 7},\n",
       " (1, 1, 4),\n",
       " (0, 1, -1),\n",
       " (0, 1, -1))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for docName, docContent in collection:\n",
    "    docIdx = len(globalDocument)\n",
    "    globalDocument.append(docName)\n",
    "    \n",
    "    localPosting = dict()\n",
    "    for term in docContent.lower().split():\n",
    "        if term in localPosting.keys():\n",
    "            localPosting[term] += 1      \n",
    "        else:\n",
    "            localPosting[term] = 1\n",
    "            \n",
    "    ############################################# Local   \n",
    "    \n",
    "    for term, freq in localPosting.items():\n",
    "        if term in globalLexicon.keys():\n",
    "            # Lexicon term ? => Posting 기록, 위치를 업데이트\n",
    "            termIdx = list(globalLexicon.keys()).index(term)\n",
    "            postingIdx = len(globalPosting)\n",
    "            globalPosting.append((docIdx, freq, globalLexicon[term]))\n",
    "            globalLexicon[term] = postingIdx\n",
    "        else:\n",
    "            # Posting 기록, 위치도 기록\n",
    "            termIdx = len(globalLexicon.keys())\n",
    "            postingIdx = len(globalPosting)       \n",
    "            globalPosting.append((docIdx, freq, -1))\n",
    "            globalLexicon[term] = postingIdx\n",
    "            \n",
    "globalLexicon, globalPosting[8], globalPosting[4], globalPosting[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this\n",
      " 2-Document1, 1, Next=5\n",
      " 1-Document2, 1, Next=0\n",
      " 0-Document3, 1, Next=-1\n",
      "is\n",
      " 2-Document1, 1, Next=6\n",
      " 1-Document2, 1, Next=1\n",
      " 0-Document3, 1, Next=-1\n",
      "not\n",
      " 0-Document3, 1, Next=-1\n",
      "a\n",
      " 2-Document1, 1, Next=3\n",
      " 0-Document3, 1, Next=-1\n",
      "sample\n",
      " 2-Document1, 1, Next=8\n",
      " 1-Document2, 1, Next=4\n",
      " 0-Document3, 1, Next=-1\n",
      "another\n",
      " 1-Document2, 1, Next=-1\n"
     ]
    }
   ],
   "source": [
    "for term, postingIdx in globalLexicon.items(): # TDM.keys()\n",
    "    print(term)\n",
    "    \n",
    "    while True:\n",
    "        if postingIdx == -1:\n",
    "            break\n",
    "         \n",
    "        data = globalPosting[postingIdx]\n",
    "        print(' {0}-{1}, {2}, Next={3}'.format(data[0], \n",
    "                                               globalDocument[data[0]],\n",
    "                                               data[1],\n",
    "                                               data[2]))\n",
    "        postingIdx = data[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF\n",
    "# 특정 문서 내 특정 단어의 빈도 = f(t,d) - OK\n",
    "# 특정 문서 내 다른 단어의 빈도 => sum, max - DTM(sum, max)\n",
    "from math import log10\n",
    "\n",
    "def logTF(freq):\n",
    "    return log10(1+freq)\n",
    "\n",
    "def totalTF(freq, totalFreq):\n",
    "    return freq/totalFreq\n",
    "\n",
    "def doubleTF(freq, maxFreq, alpha=0.5):\n",
    "    return alpha+(1-alpha)*(freq/maxFreq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDF\n",
    "# 전체 문서의 갯수 => N\n",
    "# 특정 단어가 나타난 문서의 갯수 => dt(t)\n",
    "def idf(df, N):\n",
    "    return log10(N/df)\n",
    "\n",
    "def smoothingIdf(df, N):\n",
    "    return log10(N/(1+df))\n",
    "\n",
    "def probabilityIdf(df, N):\n",
    "    return log10((N-df+1)/df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this - DF:3, N:3\n",
      "    IDF1:0.0\n",
      "    IDF2:-0.12493873660829995\n",
      "    IDF3:-0.47712125471966244\n",
      "\n",
      "is - DF:3, N:3\n",
      "    IDF1:0.0\n",
      "    IDF2:-0.12493873660829995\n",
      "    IDF3:-0.47712125471966244\n",
      "\n",
      "not - DF:1, N:3\n",
      "    IDF1:0.47712125471966244\n",
      "    IDF2:0.17609125905568124\n",
      "    IDF3:0.47712125471966244\n",
      "\n",
      "a - DF:2, N:3\n",
      "    IDF1:0.17609125905568124\n",
      "    IDF2:0.0\n",
      "    IDF3:0.0\n",
      "\n",
      "sample - DF:3, N:3\n",
      "    IDF1:0.0\n",
      "    IDF2:-0.12493873660829995\n",
      "    IDF3:-0.47712125471966244\n",
      "\n",
      "another - DF:1, N:3\n",
      "    IDF1:0.47712125471966244\n",
      "    IDF2:0.17609125905568124\n",
      "    IDF3:0.47712125471966244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "N = len(globalDocument)\n",
    "\n",
    "for term, postingIdx in globalLexicon.items():\n",
    "    df = 0    \n",
    "    while True:\n",
    "        if postingIdx == -1:\n",
    "            break\n",
    "        df += 1\n",
    "        data = globalPosting[postingIdx]\n",
    "        \n",
    "        postingIdx = data[2]\n",
    "    print('{0} - DF:{1}, N:{2}'.format(term, df, N))\n",
    "    print('    IDF1:{0}'.format(idf(df, N)))\n",
    "    print('    IDF2:{0}'.format(smoothingIdf(df, N)))\n",
    "    print('    IDF3:{0}'.format(probabilityIdf(df, N)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = {\n",
    "    ('Document1', 'This is a a a a a a a a sample'),\n",
    "    ('Document2', 'This is another sample'),\n",
    "    ('Document3', 'This is not a sample')\n",
    "}\n",
    "\n",
    "globalLexicon = dict()\n",
    "globalDocument = list()\n",
    "globalPosting = list()\n",
    "globalMaxTF = dict()\n",
    "globalTotalTF = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for docName, docContent in collection:\n",
    "    docIdx = len(globalDocument)\n",
    "    globalDocument.append(docName)\n",
    "    \n",
    "    localPosting = dict()\n",
    "    for term in docContent.lower().split():\n",
    "        if term in localPosting.keys():\n",
    "            localPosting[term] += 1      \n",
    "        else:\n",
    "            localPosting[term] = 1\n",
    "            \n",
    "    globalMaxTF[docIdx] = max(localPosting.values())\n",
    "    globalTotalTF[docIdx] = sum(localPosting.values())\n",
    "    \n",
    "    ############################################# Local   \n",
    "    \n",
    "    for term, freq in localPosting.items():\n",
    "        if term in globalLexicon.keys():\n",
    "            # Lexicon term ? => Posting 기록, 위치를 업데이트\n",
    "            termIdx = list(globalLexicon.keys()).index(term)\n",
    "            postingIdx = len(globalPosting)\n",
    "            globalPosting.append((docIdx, freq, globalLexicon[term]))\n",
    "            globalLexicon[term] = postingIdx\n",
    "        else:\n",
    "            # Posting 기록, 위치도 기록\n",
    "            termIdx = len(globalLexicon.keys())\n",
    "            postingIdx = len(globalPosting)       \n",
    "            globalPosting.append((docIdx, freq, -1))\n",
    "            globalLexicon[term] = postingIdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this - DocIdx:2, TF:1, Max1, Total:4\n",
      "   TF1:0.3010299956639812\n",
      "   TF2:0.25\n",
      "   TF3:1.0\n",
      "this - DocIdx:1, TF:1, Max8, Total:11\n",
      "   TF1:0.3010299956639812\n",
      "   TF2:0.09090909090909091\n",
      "   TF3:0.5625\n",
      "this - DocIdx:0, TF:1, Max1, Total:5\n",
      "   TF1:0.3010299956639812\n",
      "   TF2:0.2\n",
      "   TF3:1.0\n",
      "this - DF:3, N:3\n",
      "    IDF1:0.0\n",
      "    IDF2:-0.12493873660829995\n",
      "    IDF3:-0.47712125471966244\n",
      "\n",
      "is - DocIdx:2, TF:1, Max1, Total:4\n",
      "   TF1:0.3010299956639812\n",
      "   TF2:0.25\n",
      "   TF3:1.0\n",
      "is - DocIdx:1, TF:1, Max8, Total:11\n",
      "   TF1:0.3010299956639812\n",
      "   TF2:0.09090909090909091\n",
      "   TF3:0.5625\n",
      "is - DocIdx:0, TF:1, Max1, Total:5\n",
      "   TF1:0.3010299956639812\n",
      "   TF2:0.2\n",
      "   TF3:1.0\n",
      "is - DF:3, N:3\n",
      "    IDF1:0.0\n",
      "    IDF2:-0.12493873660829995\n",
      "    IDF3:-0.47712125471966244\n",
      "\n",
      "not - DocIdx:0, TF:1, Max1, Total:5\n",
      "   TF1:0.3010299956639812\n",
      "   TF2:0.2\n",
      "   TF3:1.0\n",
      "not - DF:1, N:3\n",
      "    IDF1:0.47712125471966244\n",
      "    IDF2:0.17609125905568124\n",
      "    IDF3:0.47712125471966244\n",
      "\n",
      "a - DocIdx:1, TF:8, Max8, Total:11\n",
      "   TF1:0.9542425094393249\n",
      "   TF2:0.7272727272727273\n",
      "   TF3:1.0\n",
      "a - DocIdx:0, TF:1, Max1, Total:5\n",
      "   TF1:0.3010299956639812\n",
      "   TF2:0.2\n",
      "   TF3:1.0\n",
      "a - DF:2, N:3\n",
      "    IDF1:0.17609125905568124\n",
      "    IDF2:0.0\n",
      "    IDF3:0.0\n",
      "\n",
      "sample - DocIdx:2, TF:1, Max1, Total:4\n",
      "   TF1:0.3010299956639812\n",
      "   TF2:0.25\n",
      "   TF3:1.0\n",
      "sample - DocIdx:1, TF:1, Max8, Total:11\n",
      "   TF1:0.3010299956639812\n",
      "   TF2:0.09090909090909091\n",
      "   TF3:0.5625\n",
      "sample - DocIdx:0, TF:1, Max1, Total:5\n",
      "   TF1:0.3010299956639812\n",
      "   TF2:0.2\n",
      "   TF3:1.0\n",
      "sample - DF:3, N:3\n",
      "    IDF1:0.0\n",
      "    IDF2:-0.12493873660829995\n",
      "    IDF3:-0.47712125471966244\n",
      "\n",
      "another - DocIdx:2, TF:1, Max1, Total:4\n",
      "   TF1:0.3010299956639812\n",
      "   TF2:0.25\n",
      "   TF3:1.0\n",
      "another - DF:1, N:3\n",
      "    IDF1:0.47712125471966244\n",
      "    IDF2:0.17609125905568124\n",
      "    IDF3:0.47712125471966244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "N = len(globalDocument)\n",
    "\n",
    "for term, postingIdx in globalLexicon.items():\n",
    "    df = 0    \n",
    "    while True:\n",
    "        if postingIdx == -1:\n",
    "            break\n",
    "        df += 1\n",
    "        data = globalPosting[postingIdx]\n",
    "        \n",
    "        print('{0} - DocIdx:{1}, TF:{2}, Max{3}, Total:{4}'.format(\n",
    "            term, data[0], data[1], globalMaxTF[data[0]], globalTotalTF[data[0]]))\n",
    "        \n",
    "        print('   TF1:{0}'.format(logTF(data[1])))\n",
    "        print('   TF2:{0}'.format(totalTF(data[1], globalTotalTF[data[0]])))\n",
    "        print('   TF3:{0}'.format(doubleTF(data[1], globalMaxTF[data[0]])))\n",
    "        \n",
    "        postingIdx = data[2]\n",
    "        \n",
    "    print('{0} - DF:{1}, N:{2}'.format(term, df, N))\n",
    "    print('    IDF1:{0}'.format(idf(df, N)))\n",
    "    print('    IDF2:{0}'.format(smoothingIdf(df, N)))\n",
    "    print('    IDF3:{0}'.format(probabilityIdf(df, N)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this-Document2\n",
      " => 1.0 * 0.0 = 0.0\n",
      " => 1.0 * -0.12493873660829995 = -0.12493873660829995\n",
      " => 1.0 * -0.47712125471966244 = -0.47712125471966244\n",
      "this-Document1\n",
      " => 0.5625 * 0.0 = 0.0\n",
      " => 0.5625 * -0.12493873660829995 = -0.07027803934216872\n",
      " => 0.5625 * -0.47712125471966244 = -0.2683807057798101\n",
      "this-Document3\n",
      " => 1.0 * 0.0 = 0.0\n",
      " => 1.0 * -0.12493873660829995 = -0.12493873660829995\n",
      " => 1.0 * -0.47712125471966244 = -0.47712125471966244\n",
      "\n",
      "is-Document2\n",
      " => 1.0 * 0.0 = 0.0\n",
      " => 1.0 * -0.12493873660829995 = -0.12493873660829995\n",
      " => 1.0 * -0.47712125471966244 = -0.47712125471966244\n",
      "is-Document1\n",
      " => 0.5625 * 0.0 = 0.0\n",
      " => 0.5625 * -0.12493873660829995 = -0.07027803934216872\n",
      " => 0.5625 * -0.47712125471966244 = -0.2683807057798101\n",
      "is-Document3\n",
      " => 1.0 * 0.0 = 0.0\n",
      " => 1.0 * -0.12493873660829995 = -0.12493873660829995\n",
      " => 1.0 * -0.47712125471966244 = -0.47712125471966244\n",
      "\n",
      "not-Document3\n",
      " => 1.0 * 0.47712125471966244 = 0.47712125471966244\n",
      " => 1.0 * 0.17609125905568124 = 0.17609125905568124\n",
      " => 1.0 * 0.47712125471966244 = 0.47712125471966244\n",
      "\n",
      "a-Document1\n",
      " => 1.0 * 0.17609125905568124 = 0.17609125905568124\n",
      " => 1.0 * 0.0 = 0.0\n",
      " => 1.0 * 0.0 = 0.0\n",
      "a-Document3\n",
      " => 1.0 * 0.17609125905568124 = 0.17609125905568124\n",
      " => 1.0 * 0.0 = 0.0\n",
      " => 1.0 * 0.0 = 0.0\n",
      "\n",
      "sample-Document2\n",
      " => 1.0 * 0.0 = 0.0\n",
      " => 1.0 * -0.12493873660829995 = -0.12493873660829995\n",
      " => 1.0 * -0.47712125471966244 = -0.47712125471966244\n",
      "sample-Document1\n",
      " => 0.5625 * 0.0 = 0.0\n",
      " => 0.5625 * -0.12493873660829995 = -0.07027803934216872\n",
      " => 0.5625 * -0.47712125471966244 = -0.2683807057798101\n",
      "sample-Document3\n",
      " => 1.0 * 0.0 = 0.0\n",
      " => 1.0 * -0.12493873660829995 = -0.12493873660829995\n",
      " => 1.0 * -0.47712125471966244 = -0.47712125471966244\n",
      "\n",
      "another-Document2\n",
      " => 1.0 * 0.47712125471966244 = 0.47712125471966244\n",
      " => 1.0 * 0.17609125905568124 = 0.17609125905568124\n",
      " => 1.0 * 0.47712125471966244 = 0.47712125471966244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "N = len(globalDocument)\n",
    "\n",
    "for term, postingIdx in globalLexicon.items():\n",
    "    old = postingIdx\n",
    "    df = 0    \n",
    "    while True:\n",
    "        if postingIdx == -1:\n",
    "            break\n",
    "        df += 1\n",
    "        postingIdx = globalPosting[postingIdx][2]\n",
    "        \n",
    "    \n",
    "    postingIdx = old\n",
    "    idf1 = idf(df, N)\n",
    "    idf2 = smoothingIdf(df, N)\n",
    "    idf3 = probabilityIdf(df, N)\n",
    "    \n",
    "    while True:\n",
    "        if postingIdx == -1:\n",
    "            break\n",
    "\n",
    "        data = globalPosting[postingIdx]\n",
    "        postingIdx = data[2]\n",
    "        tf = doubleTF(data[1], globalMaxTF[data[0]])\n",
    "        print('{0}-{1}'.format(term, globalDocument[data[0]]))\n",
    "        print(' => {0} * {1} = {2}'.format(tf, idf1, tf*idf1))\n",
    "        print(' => {0} * {1} = {2}'.format(tf, idf2, tf*idf2))\n",
    "        print(' => {0} * {1} = {2}'.format(tf, idf3, tf*idf3))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
